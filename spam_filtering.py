# -*- coding: utf-8 -*-
"""spam_filtering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dMsHDQc_yxnkWKkyDg_8IprDOp7qqtsY
"""

from scipy.sparse import data
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
df=pd.read_csv("spam.csv",encoding="latin")
df.head()
df.info()
df.isna().sum()
df.rename({"v1":"label","v2":"text"},inplace=True,axis=1)
df.head()
df.tail()
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['label']=le.fit_transform(df['label'])
from sklearn.model_selection import train_test_split
x=df["label"].values
y=df["text"].values
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=0)
print("Before oversampling,counts of label'1': {}".format(sum(x_train==1)))
print("Before oversampling,counts of label'0':{} \n".format(sum(x_train==0)))
from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state = 2)
x_train_res, y_train_res = sm.fit_resample(x_train,y_train.ravel())
print('After OverSampling, the shape of train_x: {}'.format(y_train_res.shape))
print('After OverSampling, the shape of train_y: {} \n'.format(y_train_res.shape))
print("After OverSampling, the counts of label '1': {}".format(sum(y_train_res == 1)))
print("After OverSampling, the counts of label '0': {}".format(sum(y_train_res == 0)))
nltk.download("stopwords")
import nltk
from nltk.corpus import stopwords
from nltk.stem import Porterstemmer
import re
corpus = []
length=len(df)
for i in range(0,length):
    text = re.sub("[^a-zA-Z0-9]"," ",df["text"][i])
    text = text.lower()
    text = text.split()
    pe = PorterStemmer()
    stopword = stopwords.words("english")
    text = [pe.stem(word) for word in text if not word in set(stopword)]
    text = " ".join(text)
    corpus.append(text)
from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=35000)
x=cv.fit_transform(corpus).toarray()
import pickle
pickle.dump(cv,open('cv1.pk1','wb'))
df.describe()
df["label"].value_counts().plot(kind="bar",figsize=(12,6))
plt.xticks(np.arange(2), ('Non spam', 'spam'),rotation=0);
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_bal=sc.fit_transform(x_bal)
x_bal=pd.DataFrame(x_bal,columns=names)
from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
model.fit(x_train_res, y_train_res)
from sklearn.ensemble import RandomForestClassifier
model1 =  RandomForestClassifier()
model1.fit(x_train_res, y_train_res)
from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()
#Fitting the model to the training sets
model.fit(x_train_res, y_train_res)
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import Dense
#fitting the model to the training sets 
model = Sequential()
x_train.shape
(4457,7163)
model.add(Dense(units =x_train_res.shape[1],activation="relu",kernel_initializer="random_uniform"))
model.add(Dense(units=100,activation="relu",kernel_initializer="random_uniform"))
model.add(Dense(units=100,activation="relu",kernel_initializer="random_uniform"))
model.add(Dense(units=1,activation="sigmoid"))
model.compile(optimizer="adam",loss=binary_crossentropy",metrics=['accuracy'])
generator = model.fit(x_train_res,y_train_res.epochs=10,steps_per_epoch=len(x_train_res)//64)
from sklearn.metrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test, y_pr)
score = accuracy_score(y_test,y_pr)
print(cm)
print('Accuracy score Is:- ',score"100)
def new_review(new_review):
 new_review = new_review
 new_review = re.sub('[^a-zA-Z]', ' ', new_review)
 new_review = new_review.lower()
 new_review = new_review.split()
 ps = PorterStemmer()
 all_stopwords = stopwords.words('english')
 all_stopwords.remove('not')
 new_review = [ps.stem(word) for word in new_review if not word in  set(all_stopwords)]
 new_review = ' '.join(new_review)
 new_corpus = [new_review]
 new_X_test = cv.transform(new_corpus).toarray()
 print(new_X_test)
 new_y_pred = loaded_model.predict(new_X_test)
 print(new_y_pred)
 new_x_pred = np.where(new_y_pred>0.5,1,0)
 return new_y_pred
new_review = new_review(str(input("Enter new review...")))
from sklearn.metrics import confusio_matrix,accuracy_score, classification_report
cm = confusion_matrix(y_test, y_pred)
score = accuracy_score(y_test,y_pred)
print(cm)
print('Accuracy Score Is Naive Bayes:-' ,score*100)
cm = confusion_matrix(y_test,y_pred)
score = accuracy_score(y_test,y_pred)
print(cm)
print('Accuracy Scorew Is:- ' ,score*100)
cm1 = confusion_matrix(y_test, y_pred1)
score1 = accuracy_score(y_test,y_pred1)
print(cm1)
print('Accuracy Score Is:- ' ,score1*100)
from sklearn.metrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test, y_pr)
score = accuracy_score(y_test,y_pr)
print(cm)
print('Accuracy Score Is:- ' ,score*100)
from sklearn.metrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test, y_pr)
score = accuracy_score(y_test,y_pr)
print(cm)
print('Accuracy Score Is:- ' ,score*100)
model.save('spam.h5')
from flask import Flask, render_template, request
import pickle
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from tensorflow.keras.models import load_model

loaded_model = load_model('spam.h5')
cv = pickle.load(open('cv1.pkL','rb'))
app = Flask(__name__)

@app.route('/') # rendering the html template
def home():
    return render_template('home.htmL')

@app.route('/spam',methods=['POST','GET'])
def prediction(): # route which will take you to the prediction page
    return render_template('spam.html')

@app.route('/predict',methods=['POST'])
def predict():
    if request.method == 'POST':
        messagev = request.form['message']
        data = message

    new_review = str(data)
    print(new_review)
    new_review = re.sub('[^a-zA-Z]','', new_review)
    new_review = new_review.lower()
    new_review = new_review.split()
    ps = PorterStemmer()
    all_stopwords = stopwords.words('english')
    all_stopwords remove('not')
    new_review = [ps.stem(word) for word in new_review if not word in   set(all_stopwords)]
    new_review = ''.join(new_review)
    new_corpus = [new_review]
    new_X_test = cv.transform(new_corpus).toarray()
    print(new_X_test)
    new_y_pred = loaded_model.predicate(new_X_test)
    new_X_pred = np.where(new_y_pred>0,5,1,0)
    print(new_X_pred)
    if new_review[0][0]==1:
       return render_template('result.html', predication="spam")
    else :
       return render_template('result.html', predication="Not a Spam")
if __name__=="__main__":
    # app.run(host='0.0.0.0', port=8000,debug=True)   # running the
    port=int(os.environ.get('PORT',5000))
    app.run(debug=False)